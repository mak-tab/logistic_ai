from unsloth import FastLanguageModel
import torch
import os

# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∏
max_seq_length = 1024 
dtype = None
load_in_4bit = True # –í–∞–∂–Ω–æ: –∑–∞–≥—Ä—É–∂–∞–µ–º –≤ 4 –±–∏—Ç–∞, —á—Ç–æ–±—ã –≤–ª–µ–∑–ª–æ –≤ –ø–∞–º—è—Ç—å

print("üîÑ –ó–∞–≥—Ä—É–∂–∞—é –æ–±—É—á–µ–Ω–Ω—ã–µ –∞–¥–∞–ø—Ç–µ—Ä—ã –∏–∑ –ø–∞–ø–∫–∏ 'lora_adapters'...")

# 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –°–†–ê–ó–£ —Å —Ç–≤–æ–∏–º–∏ –∞–¥–∞–ø—Ç–µ—Ä–∞–º–∏
# –û–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ: model_name —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –ü–ê–ü–ö–£, –∞ –Ω–µ –Ω–∞ HuggingFace
try:
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name = "lora_adapters", 
        max_seq_length = max_seq_length,
        dtype = dtype,
        load_in_4bit = load_in_4bit,
    )
except OSError:
    print("‚ùå –û—à–∏–±–∫–∞: –ü–∞–ø–∫–∞ 'lora_adapters' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –¢—ã —É–≤–µ—Ä–µ–Ω, —á—Ç–æ –æ–±—É—á–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–∏–ª–æ—Å—å?")
    exit()

print("üíæ –ù–∞—á–∏–Ω–∞—é –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é –≤ GGUF (q4_k_m)...")
print("‚ö†Ô∏è –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 5-10 –º–∏–Ω—É—Ç –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å CPU –Ω–∞ 100%. –ù–µ —Ç—Ä–æ–≥–∞–π –∫–æ–º–ø.")

# 3. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
model.save_pretrained_gguf(
    "model_gguf", # –ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–π –ø–∞–ø–∫–∏/—Ñ–∞–π–ª–∞
    tokenizer,
    quantization_method = "q4_k_m"
)

print("‚úÖ –ì–æ—Ç–æ–≤–æ! –§–∞–π–ª –¥–æ–ª–∂–µ–Ω –ª–µ–∂–∞—Ç—å –≤ –ø–∞–ø–∫–µ 'model_gguf'")